# Reliability Issues from HPC to AI
### Paolo Rech

## Radiation reliability
Cosmic rays go *BZZZZZ*, causing:
- Detected Unrecoverable Error (DUE)
- Silent Data Corruption

Radiations comes from space in form of Ions and Protons by:
1. galactic cosmic rays
2. Solar wind and flares
3. Van Allen belts

We are usually protected by the Van Allen belts but sometimes
the radiations are so powerful that the magnetic field of the
earth is not enough to stop them.

The galactic rays that comes from space when hits the earth
produces a cascade of molecules, the dangerous one for electric
computers are *electrons*.

When an electron hits a transistor, it deposits a lot of energy
in it, activating it even when it should be off.
You can experience:
- One or more bitflips
- Logic faults

Those errors, even if they don't kill hardware, are silent, so
you can have errors without knowing why.

You also have a big problem with shrinking transistor size:
the smaller the transistor, the easier for the electron ray to
hit it.
Nowadays, with 3-7nm transistor, even a single ray can hit more
transistors, causing a big problem.

## Reliability requirements
Different devices will require a different level of reliability.

You go from consumer hardware that have low reliability requirements
to HPC/Datacenter/Automotive/Space industries that have very high
requirements.

But unfortunately the hardware used in all those scenarios, is
almost the same.

So there's a big need for software control for reliability issues.

They do radiation experiments by exposing hardware setup to high
radiation environments (usually involving particle accelerators).

Probability for neutron to generate an error
Cross Section * Flux (@ sea level) = Error Rate

The error rate of a single GPU is around 1 every 3.5 years,
but in HPC settings, you can easily expect >18k of those GPUs, so
you amount to ~15 errors per day.

## How to deal with it?
The easiest solution is to duplicate hardware, but is not cost
effective at all. Another way is to set computation checkpoints.

But it turns out that the way in which you write the code can effect
the error rate and especially how the error propagate through the code

General optimization is a good way to increase reliability, since
even if you will do more calculation, thus having more error, you
will create more output, thus decreasing error rate.

Even parallelizing code will increase total error but decrease error rate
for the same reason.

> Increasing performance is the principal way to increase reliability
> without increasing cost

Reducing precision for example is very effective.

## Alternatives?
If you're able to to have unused parallel parts, you can run computations
in low precision on those part of the HW to compare results with the normal
high precisions ones.

In this way researcher have been able to detect around 70% of errors.

